---
# ============================================================================
# SPEC METADATA - This entire frontmatter section contains the spec metadata
# ============================================================================

# === IDENTIFICATION ===
id: 1579779b # Unique identifier (never changes)
title: Docker Compose CI Testing Environment
type: task

# === HIERARCHY ===
parent: 'E01-F04'
children: []
epic: 'E01'
domain: infrastructure

# === WORKFLOW ===
status: draft
priority: medium

# === TRACKING ===
created: '2025-08-28'
updated: '2025-08-28'
due_date: ''
estimated_hours: 2
actual_hours: 0

# === METADATA ===
tags:
  - docker-compose
  - testing
  - ci
  - integration
effort: small
risk: low
---

# Docker Compose CI Testing Environment

## Overview

Configure Docker Compose setup for CI/CD pipeline testing with all required services (PostgreSQL, ClickHouse, MongoDB, Redis, Kafka) optimized for fast startup and teardown. This setup provides isolated, reproducible testing environments for integration tests in GitHub Actions with minimal resource overhead and maximum performance.

## Acceptance Criteria

- [ ] **Service Configuration**: All required databases and message queues with CI-optimized settings
- [ ] **Performance Optimization**: tmpfs for data directories and minimal logging
- [ ] **Health Checks**: Wait-for-ready scripts with timeout handling
- [ ] **Network Isolation**: Dedicated CI network with proper service discovery
- [ ] **Resource Limits**: Memory and CPU constraints for CI runners
- [ ] **Fast Startup**: Optimized for CI speed (<30 seconds total startup)
- [ ] **Data Fixtures**: Test data seeding scripts with clean state guarantee
- [ ] **Cleanup Scripts**: Proper teardown after tests with volume cleanup
- [ ] **GitHub Actions Integration**: Seamless workflow integration with caching
- [ ] **Environment Variables**: Secure configuration management for CI

## Technical Implementation

### Main Docker Compose Configuration

**`docker-compose.ci.yml`**:

```yaml
version: '3.8'

networks:
  jts-ci:
    driver: bridge
    name: jts-ci-${GITHUB_RUN_ID:-local}

volumes:
  postgres_data:
    driver_opts:
      type: tmpfs
      device: tmpfs
  clickhouse_data:
    driver_opts:
      type: tmpfs
      device: tmpfs
  mongodb_data:
    driver_opts:
      type: tmpfs
      device: tmpfs
  kafka_data:
    driver_opts:
      type: tmpfs
      device: tmpfs

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: jts_test
      POSTGRES_USER: jts_user
      POSTGRES_PASSWORD: test_password
      POSTGRES_INITDB_ARGS: '--no-fsync --no-sync'
    command: >
      postgres 
      -c fsync=off 
      -c synchronous_commit=off 
      -c full_page_writes=off 
      -c wal_buffers=8MB 
      -c checkpoint_segments=32
      -c checkpoint_completion_target=0.9
      -c shared_buffers=128MB
      -c work_mem=4MB
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/ci/postgres-init.sql:/docker-entrypoint-initdb.d/01-init.sql
    networks:
      - jts-ci
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U jts_user -d jts_test']
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  clickhouse:
    image: clickhouse/clickhouse-server:23-alpine
    environment:
      CLICKHOUSE_DB: jts_market
      CLICKHOUSE_USER: jts_user
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
      CLICKHOUSE_PASSWORD: test_password
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./scripts/ci/clickhouse-config.xml:/etc/clickhouse-server/config.d/config.xml
      - ./scripts/ci/clickhouse-users.xml:/etc/clickhouse-server/users.d/users.xml
    networks:
      - jts-ci
    healthcheck:
      test: ['CMD', 'clickhouse-client', '--query', 'SELECT 1']
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  mongodb:
    image: mongo:7-jammy
    environment:
      MONGO_INITDB_ROOT_USERNAME: jts_user
      MONGO_INITDB_ROOT_PASSWORD: test_password
      MONGO_INITDB_DATABASE: jts_config
    command: --storageEngine inMemory --nojournal --noprealloc --smallfiles
    volumes:
      - mongodb_data:/data/db
      - ./scripts/ci/mongo-init.js:/docker-entrypoint-initdb.d/init.js
    networks:
      - jts-ci
    healthcheck:
      test: ['CMD', 'mongosh', '--eval', "db.adminCommand('ping')"]
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly no --save "" --maxmemory 128m --maxmemory-policy allkeys-lru
    volumes:
      - /dev/shm:/data
    networks:
      - jts-ci
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_LOG_SEGMENT_BYTES: 1048576
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - jts-ci
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ['CMD-SHELL', 'kafka-broker-api-versions --bootstrap-server localhost:9092']
      interval: 10s
      timeout: 10s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
    volumes:
      - /dev/shm:/var/lib/zookeeper/data
      - /dev/shm:/var/lib/zookeeper/log
    networks:
      - jts-ci
    healthcheck:
      test: ['CMD-SHELL', 'echo ruok | nc localhost 2181 | grep imok']
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
```

### Health Check and Wait Scripts

**`scripts/ci/wait-for-services.sh`**:

```bash
#!/bin/bash
set -e

SERVICES=("postgres:5432" "clickhouse:8123" "mongodb:27017" "redis:6379" "kafka:9092")
TIMEOUT=120
INTERVAL=5

echo "Waiting for services to be ready..."

wait_for_service() {
  local service=$1
  local host=${service%:*}
  local port=${service#*:}

  echo "Checking $service..."

  timeout $TIMEOUT bash -c "
    until nc -z $host $port; do
      sleep $INTERVAL
    done
  "

  echo "$service is ready!"
}

# Wait for all services in parallel
for service in "${SERVICES[@]}"; do
  wait_for_service "$service" &
done

wait

# Verify database connections
echo "Verifying database connections..."

# PostgreSQL
PGPASSWORD=test_password psql -h postgres -U jts_user -d jts_test -c "SELECT 1;" > /dev/null

# ClickHouse
clickhouse-client --host clickhouse --user jts_user --password test_password --query "SELECT 1" > /dev/null

# MongoDB
mongosh --host mongodb --username jts_user --password test_password --eval "db.adminCommand('ping')" > /dev/null

# Redis
redis-cli -h redis ping > /dev/null

# Kafka
kafka-console-producer --bootstrap-server kafka:9092 --topic __test__ < /dev/null

echo "All services are ready and accessible!"
```

### Test Data Fixtures

**`scripts/ci/seed-test-data.sh`**:

```bash
#!/bin/bash
set -e

echo "Seeding test data..."

# PostgreSQL test data
PGPASSWORD=test_password psql -h postgres -U jts_user -d jts_test << 'EOF'
INSERT INTO users (id, username, email, created_at) VALUES
  (1, 'test_user', 'test@example.com', NOW()),
  (2, 'trader_test', 'trader@example.com', NOW());

INSERT INTO accounts (id, user_id, balance, currency) VALUES
  (1, 1, 100000.00, 'USD'),
  (2, 2, 50000.00, 'USD');

INSERT INTO strategies (id, name, parameters, active) VALUES
  (1, 'test_strategy', '{"risk_limit": 1000}', true);
EOF

# ClickHouse market data
clickhouse-client --host clickhouse --user jts_user --password test_password << 'EOF'
INSERT INTO market_data (timestamp, symbol, price, volume) VALUES
  ('2024-01-01 10:00:00', 'AAPL', 150.25, 1000),
  ('2024-01-01 10:01:00', 'AAPL', 150.30, 1500),
  ('2024-01-01 10:00:00', 'GOOGL', 2800.50, 500);
EOF

# MongoDB configuration data
mongosh --host mongodb --username jts_user --password test_password << 'EOF'
use jts_config;
db.brokers.insertMany([
  {
    name: "test_broker",
    type: "mock",
    enabled: true,
    config: { api_key: "test_key" }
  }
]);

db.markets.insertMany([
  { symbol: "AAPL", exchange: "NASDAQ", active: true },
  { symbol: "GOOGL", exchange: "NASDAQ", active: true }
]);
EOF

# Redis cache warming
redis-cli -h redis << 'EOF'
SET test:key "test_value"
HSET user:1 name "Test User" balance "100000"
EOF

echo "Test data seeded successfully!"
```

### GitHub Actions Integration

**`scripts/ci/docker-compose-ci.yml`** (GitHub Actions workflow):

```yaml
name: CI Tests with Docker Compose

on:
  pull_request:
  push:
    branches: [main, develop]

env:
  COMPOSE_FILE: docker-compose.ci.yml
  COMPOSE_PROJECT_NAME: jts-ci-${{ github.run_id }}

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Cache Docker Images
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-docker-${{ hashFiles('docker-compose.ci.yml') }}
          restore-keys: |
            ${{ runner.os }}-docker-

      - name: Start Services
        run: |
          docker-compose -f docker-compose.ci.yml up -d
          chmod +x scripts/ci/wait-for-services.sh
          ./scripts/ci/wait-for-services.sh

      - name: Seed Test Data
        run: |
          chmod +x scripts/ci/seed-test-data.sh
          ./scripts/ci/seed-test-data.sh

      - name: Run Integration Tests
        run: |
          npm run test:integration
        env:
          DATABASE_URL: postgresql://jts_user:test_password@localhost:5432/jts_test
          CLICKHOUSE_URL: http://jts_user:test_password@localhost:8123/jts_market
          MONGODB_URL: mongodb://jts_user:test_password@localhost:27017/jts_config
          REDIS_URL: redis://localhost:6379
          KAFKA_BROKERS: localhost:9092

      - name: Collect Container Logs
        if: failure()
        run: |
          docker-compose -f docker-compose.ci.yml logs --tail=100 > container-logs.txt

      - name: Upload Logs
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: container-logs
          path: container-logs.txt

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.ci.yml down -v --remove-orphans
          docker system prune -f
```

### Resource Optimization Scripts

**`scripts/ci/optimize-ci-environment.sh`**:

```bash
#!/bin/bash
set -e

echo "Optimizing CI environment..."

# Increase shared memory for containers
sudo mount -o remount,size=1G /dev/shm

# Optimize Docker daemon for CI
sudo tee /etc/docker/daemon.json << 'EOF'
{
  "storage-driver": "overlay2",
  "storage-opts": ["overlay2.override_kernel_check=true"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "default-ulimits": {
    "nofile": {
      "hard": 65536,
      "soft": 65536
    }
  }
}
EOF

# Restart Docker
sudo systemctl restart docker

# Pre-pull images for faster startup
docker-compose -f docker-compose.ci.yml pull

echo "CI environment optimized!"
```

### Cleanup and Teardown

**`scripts/ci/cleanup.sh`**:

```bash
#!/bin/bash

echo "Cleaning up CI environment..."

# Stop and remove containers
docker-compose -f docker-compose.ci.yml down -v --remove-orphans

# Remove unused volumes
docker volume prune -f

# Remove unused networks
docker network prune -f

# Clean up test data files
rm -rf /tmp/jts-ci-*

# Clear shared memory
sudo umount /dev/shm 2>/dev/null || true
sudo mount -t tmpfs tmpfs /dev/shm

echo "Cleanup completed!"
```

## Testing Plan

### Service Startup Tests

- Verify all services start within 30 seconds
- Test health check endpoints respond correctly
- Validate service dependency order
- Test parallel service initialization

### Integration Test Suite

- Database connectivity tests for all services
- Message queue producer/consumer tests
- Cache operations and persistence tests
- Service discovery and network communication
- Cross-service transaction tests

### Performance Benchmarks

- Measure container startup times
- Validate memory usage under resource limits
- Test concurrent connection handling
- Benchmark data seeding performance

### Failure Scenarios

- Test service restart capabilities
- Validate cleanup after failed tests
- Test network partition recovery
- Validate data consistency after crashes

## Success Metrics

- **Startup Performance**: All services ready in <30 seconds
- **Resource Usage**: Total memory usage <2GB, CPU <2 cores
- **Test Reliability**: >99% test pass rate in CI
- **Cleanup Efficiency**: Complete teardown in <10 seconds
- **Cache Hit Rate**: Docker image cache >80% hit rate
- **Parallel Execution**: Support 4+ concurrent test runs

## Environment Variables Configuration

### Required CI Variables

```bash
# Database connections
DATABASE_URL=postgresql://jts_user:test_password@postgres:5432/jts_test
CLICKHOUSE_URL=http://jts_user:test_password@clickhouse:8123/jts_market
MONGODB_URL=mongodb://jts_user:test_password@mongodb:27017/jts_config
REDIS_URL=redis://redis:6379
KAFKA_BROKERS=kafka:9092

# Service configuration
NODE_ENV=test
LOG_LEVEL=error
DISABLE_TELEMETRY=true
SKIP_AUTH=true

# Resource limits
MAX_MEMORY_USAGE=2048m
MAX_CPU_USAGE=2
```

## Notes

- Use tmpfs volumes for maximum I/O performance
- Implement circuit breakers for flaky network connections
- Consider service mesh for complex microservice testing
- Monitor container resource usage and adjust limits accordingly
- Use Docker layer caching for faster image builds
