---
# ============================================================================
# SPEC METADATA - This entire frontmatter section contains the spec metadata
# ============================================================================

# === IDENTIFICATION ===
id: ce5140df # Unique identifier (never changes)
title: Docker and Database Services Setup
type: task

# === HIERARCHY ===
parent: "E01-F02"
children: []
epic: "E01"
domain: infrastructure

# === WORKFLOW ===
status: completed
priority: high

# === TRACKING ===
created: '2025-08-27'
updated: '2025-09-01'
completed: '2025-09-01'
due_date: '2025-08-31'
estimated_hours: 3
actual_hours: 4

# === DEPENDENCIES ===
files:
  - docker-compose.dev.yml
  - .env
  - .env.example
  - configs/database/redis.conf
  - configs/clickhouse-config.xml
  - scripts/init-postgres.sql
  - scripts/database/init-mongo.js
  - scripts/build/docker-setup.sh
  - scripts/development/dev-services.sh

# === METADATA ===
tags:
  - docker
  - database
  - postgres
  - mongodb
  - redis
  - clickhouse
  - kafka
effort: medium
risk: medium
---

# Docker and Database Services Setup

## Overview

Set up Docker environment with all required database and messaging services for local development, including PostgreSQL, ClickHouse, MongoDB, Redis, Kafka, and monitoring tools. Configure multi-account support infrastructure.

## Acceptance Criteria

- [x] Docker and Docker Compose installed on Linux and Windows
- [x] PostgreSQL configured with development database
- [x] ClickHouse set up for time-series data
- [x] MongoDB configured for configuration storage
- [x] Redis configured with database allocation for multi-accounts
- [x] Kafka and Zookeeper operational
- [x] Grafana monitoring dashboard (optional)
- [x] All services accessible and healthy
- [x] Initialization scripts for databases
- [x] Volume persistence configured
- [x] Centralized port configuration via `.env` file

## Related Specs

**Dependencies:**
- [E01-F02-T01](../E01-F02-T01/spec.md)

**Blocks:**
- [E01-F02-T04](../E01-F02-T04/spec.md)
- [E01-F02-T05](../E01-F02-T05/spec.md)
- [E01-F02-T06](../E01-F02-T06/spec.md)

## Technical Approach

### Docker Compose Configuration (`docker-compose.dev.yml`)

```yaml
version: '3.8'

services:
  # PostgreSQL - Core business data
  postgres:
    image: postgres:15-alpine
    container_name: jts-postgres-dev
    restart: unless-stopped
    ports:
      - '5432:5432'
    environment:
      POSTGRES_DB: jts_trading_dev
      POSTGRES_USER: jts_admin
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init-postgres.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U jts_admin -d jts_trading_dev']
      interval: 10s
      timeout: 5s
      retries: 5

  # ClickHouse - Time-series market data
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: jts-clickhouse-dev
    restart: unless-stopped
    ports:
      - '8123:8123'
      - '9000:9000'
    environment:
      CLICKHOUSE_DB: jts_market_data_dev
      CLICKHOUSE_USER: jts_ch
      CLICKHOUSE_PASSWORD: dev_password
    volumes:
      - clickhouse_dev_data:/var/lib/clickhouse
      - ./configs/clickhouse-config.xml:/etc/clickhouse-server/config.xml
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  # MongoDB - Configuration storage
  mongodb:
    image: mongo:7
    container_name: jts-mongodb-dev
    restart: unless-stopped
    ports:
      - '27017:27017'
    environment:
      MONGO_INITDB_ROOT_USERNAME: jts_mongo
      MONGO_INITDB_ROOT_PASSWORD: dev_password
      MONGO_INITDB_DATABASE: jts_config_dev
    volumes:
      - mongodb_dev_data:/data/db
      - ./scripts/init-mongo.js:/docker-entrypoint-initdb.d/init.js

  # Redis - Caching and rate limiting
  redis:
    image: redis:7-alpine
    container_name: jts-redis-dev
    restart: unless-stopped
    ports:
      - '6379:6379'
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - redis_dev_data:/data
      - ./configs/redis.conf:/usr/local/etc/redis/redis.conf

  # Kafka & Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: jts-zookeeper-dev
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: jts-kafka-dev
    depends_on:
      - zookeeper
    ports:
      - '9092:9092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Monitoring (Optional)
  grafana:
    image: grafana/grafana:latest
    container_name: jts-grafana-dev
    ports:
      - '3100:3000'
    environment:
      GF_SECURITY_ADMIN_PASSWORD: dev_password
    volumes:
      - grafana_dev_data:/var/lib/grafana

volumes:
  postgres_dev_data:
  clickhouse_dev_data:
  mongodb_dev_data:
  redis_dev_data:
  grafana_dev_data:

networks:
  default:
    name: jts-dev-network
```

### Redis Configuration for Multi-Account (`configs/database/redis.conf`)

```conf
# Redis configuration for multi-account support
databases 16

# Database allocation with naming convention:
# 0: session:cache - Session and auth cache
# 1: kis:account:1:ratelimit - KIS account 1 rate limiting
# 2: kis:account:2:ratelimit - KIS account 2 rate limiting
# 3: kis:account:3:ratelimit - KIS account 3 rate limiting
# 4: kis:account:4:ratelimit - KIS account 4 rate limiting
# 5: kis:account:5:ratelimit - KIS account 5 rate limiting
# 6: surge:detection - Surge detection cache
# 7: order:queue - Order processing queue
# 8: metrics:account - Account metrics and analytics
# 9-15: Reserved for future expansion

save 900 1
save 300 10
save 60 10000

appendonly yes
appendfsync everysec
```

### Database Initialization Scripts

**PostgreSQL** (`scripts/init-postgres.sql`):

```sql
-- Create schemas
CREATE SCHEMA IF NOT EXISTS trading;
CREATE SCHEMA IF NOT EXISTS analytics;

-- Create tables
CREATE TABLE IF NOT EXISTS trading.orders (
    id UUID PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    account_id VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes
CREATE INDEX idx_orders_account ON trading.orders(account_id);
CREATE INDEX idx_orders_created ON trading.orders(created_at);
```

## Implementation Steps

1. **Install Docker** (30 min)
   - Linux: Docker Engine installation
   - Windows: Docker Desktop setup
   - Verify installation

2. **Create Docker Compose File** (45 min)
   - Define all services
   - Configure networking
   - Set up volumes

3. **Configure Databases** (45 min)
   - Create initialization scripts
   - Set up Redis for multi-account
   - Configure database schemas

4. **Test Services** (45 min)
   - Start all containers
   - Verify connectivity
   - Test health checks

5. **Create Helper Scripts** (15 min)
   - Start/stop scripts
   - Health check script
   - Data reset script

## Deliverables

- `docker-compose.dev.yml` - Complete Docker configuration with environment variables
- `.env` - Centralized port and credential configuration
- `.env.example` - Documentation and default configuration template
- `configs/database/redis.conf` - Redis configuration for multi-account (5 KIS accounts)
- `configs/clickhouse-config.xml` - ClickHouse configuration
- `scripts/init-postgres.sql` - PostgreSQL initialization with trading schemas
- [[[`scripts/database/init-mongo.js`](../../../../scripts/database/init-mongo.js)](../../../../scripts/database/init-mongo.js)](../../../../scripts/database/init-mongo.js) - MongoDB initialization with validated collections
- `scripts/build/docker-setup.sh` - Cross-platform Docker installation script
- [[[`scripts/development/dev-services.sh`](../../../../scripts/development/dev-services.sh)](../../../../scripts/development/dev-services.sh)](../../../../scripts/development/dev-services.sh) - Service management with ports, backup, and test commands

## Testing Plan

- Verify all containers start successfully
- Test database connections
- Validate Redis database allocation
- Check Kafka message publishing
- Test data persistence across restarts
- Verify health checks work

## Notes

- Redis databases are pre-allocated for multi-account rate limiting (supports up to 5 KIS accounts)
- Redis DB naming convention: `service:purpose:identifier` for clarity and maintainability
- Grafana is optional but recommended for monitoring
- All services use dev_password for local development only
